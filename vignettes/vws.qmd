---
title: "`vws`: Vertical Weighted Strips in R using C++"
author: Andrew M. Raim, James A. Livsey, and Kyle M. Irimata
format:
  pdf:
    fontsize: 10pt
    indent: false
    toc: true
    number-sections: true
    colorlinks: true
    link-citations: true
    prompt: false
    # template-partials: 
    #  - title.tex
    include-in-header:
      text: |
        \usepackage{common}
vignette: >
  %\VignetteIndexEntry{vws}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::pdf}
bibliography: references.bib
editor_options: 
  chunk_output_type: console
abstract: |
  TBD abstract goes here.
thanks: |
  Center for Statistical Research & Methodology, U.S. Census Bureau,
  Washington, DC, 20233, U.S.A.
  **For correspondence**`:` <andrew.raim@gmail.com>.
  **Disclaimer**`:` This document is released to inform interested parties
  of ongoing research and to encourage discussion of work in progress. Any
  views expressed are those of the authors and not those of the U.S. Census
  Bureau.
  Document was compiled `{r} format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z")`.
geometry:
  - left=0.5in
  - right=0.5in
  - top=0.75in
  - bottom=1.00in
execute:
  eval: false
#  eval: true
code-block-bg: true
code-block-border-left: "#31BAE9"
filters:
  - include-code-files
callout-icon: false
---

```{r}
#| include: false
library(vws)
library(tidyverse)

set.seed(1234)
```

# TBD {-}
::: {.callout-caution}
- Consider suppressing plotting code from the document if it gets too lengthy.
  We can mention to readers that the plotting code can be found with the
  vignette sources, or try to get them installed with the package perhaps.

- We should have a separate section where we describe doing stuff: constructing
  the proposal (special cases and general case where we override abstract
  region), refining the proposal, ...
:::

# Introduction

::: {.callout-caution title="TBD"}
This section is heavily under construction.

- Package is available from <https://github.com/andrewraim/vws> and possibly on
  CRAN(?).
- Some of the lengthier codes are not given in this document, but are
  provided in external files. The paths are relative to 
  <https://github.com/andrewraim/vws> (?, need to decide).
- An `R>` prompt is shown in some code displays to emphasize interaction via
  the console.
- For the first example, we should explain things in a lot of detail. After
  that, we can give less detail, except any new aspects.
- Let $\mathbb{1}_{A}(x)$ be the indicator function for the event $[x \in A]$.
  Make sure we're consistent about using either this notation or something else.
- We will use `ggplot2`, `dplyr` and other packages of the tidyverse
  [@Tidyverse2019] in the examples.
- Remark: We don't use Rcpp at the moment because interoperability between C++
  classes and R becomes more complicated. Therefore, the programming model is to
  code samplers in C++ and expose them as an R function
- Remark: Make sure to mention that other region types (e.g., multivariate) can be
  implemented with the API.

:::

To implement a rejection sampler with the `vws` package, the user must make use
of an existing subclass of `Region` or implement a new one. Two such subclasses
included in the package implement the univariate "constant VWS" method described
by @VWS2025:

- `RealConstRegion`: constant VWS with a continuous support.
- `IntConstRegion`: constant VWS with an integer support.

See the manual pages for each sampler for usage and examples. These two regions
are somewhat flexible and can be refined to a variety of problems. In this
vignette, we will describe the process of coding a customized region. We will
give one univariate example that makes use of the linear VWS method for
improved efficiency, and one multivariate example where the regions go beyond
intervals. To do this, we make use of the [R6](https://r6.r-lib.org) construct
for object-orientation in R [@Chang2021].

**TBD**: The example sections illustrate VWS samplers implemented using the `vws` package. The first example in [@sec-ln-norm] is described in the most explicit level of detail.


# A Brief Review of Vertical Weighted Strips {#sec-vws}

The objective of VWS is to sample from a weighted density
<!-- -->
\begin{align}
f(x) = f_0(x) / \psi, \quad
f_0(x) = w(x) g(x), \quad
\psi = \int_\Omega f_0(x) d\nu(x),
\label{eqn:weighted-target}
\end{align}
<!-- -->
where $\Omega$ is the support, $\nu$ is a dominating measure, $g$ is assumed to be a normalized density, $w(x)$ is a nonnegative weight function, and $\psi$ is a normalizing constant. We will construct a proposal of the form
<!-- -->
\begin{align*}
h(x) = h_0(x) / \psi_N, \quad
h_0(x) = \overline{w}(x) g(x), \quad
\psi_N = \int_\Omega h_0(x) d\nu(x).
\end{align*}
<!-- -->
The construction assumes that $\Omega$ is partitioned into regions $\mathcal{D}_1, \ldots, \mathcal{D}_N$ and there are corresponding functions $\overline{w}_j$ such that $\overline{w}_j(x) \geq w(x)$ for each $x \in \mathcal{D}_j$. We say that $\overline{w}_j$ *majorizes* $w$ on $\Omega$. Taking $\overline{w}$ as $\overline{w}(x) = \sum_{j=1}^N \overline{w}_j(x) \mathbb{1}_{\mathcal{D}_j}(x)$, the unnormalized proposal becomes
<!-- -->
\begin{align*}
h_0(x) = g(x) \sum_{j=1}^N \overline{w}_j(x) \mathbb{1}_{\mathcal{D}_j}(x).
\end{align*}
<!-- -->
With this construction, $f_0(x) \leq h_0(x)$ for all $x \in \Omega$. Therefore, classical rejection sampling can be carried out by drawing $u$ from $\text{Uniform}(0,1)$, $x$ from $h$, and accepting $x$ as a draw from $f$ if $u \leq f_0(x) / h_0(x)$. The normalized $h$ can be obtained by defining $\overline{\xi}_j = \E[\overline{w}_j(T) \mathbb{1}_{\mathcal{D}_j}(T)]$ with $T \sim g$ and $\psi_N = \sum_{j=1}^N \overline{\xi}_j$, giving the finite mixture
<!-- -->
\begin{align}
h(x)
= h_0(x) / \psi_N
= \sum_{j=1}^N \pi_j g_j(x),
\label{eqn:fmm-proposal}
\end{align}
<!-- -->
Equation \eqref{eqn:fmm-proposal} is seen to be a finite mixture with mixing weights $\pi_j = \overline{\xi}_j / \{ \sum_{\ell=1}^N \overline{\xi}_\ell \}$, and component densities
<!-- -->
\begin{align*}
g_j(x) = 
\overline{w}_j(x) g(x) \mathbb{1}_{\mathcal{D}_j}(x) / \overline{\xi}_j,
\end{align*}
<!-- -->
which are truncated and reweighted versions of base distribution $g$. In addition to the majorizer, suppose that $\underline{w}_j$ is a minorizer of $w$ so that
$0 \leq \underline{w}_j(x) \leq w(x)$ for all $x \in \mathcal{D}_j$,
and let $\underline{\xi}_j = \E[\underline{w}_j(T) \ind(T \in \mathcal{D}_j)]$ with $T \sim g$. When $h$ is used as a proposal in rejection sampling, an upper bound for the probability of rejection is
<!-- -->
\begin{align}
1 - \frac{\sum_{j=1}^N \underline{\xi}_j}{\sum_{j=1}^N \overline{\xi}_j}.
\label{eqn:bound}
\end{align}
<!-- -->
This bound can be used to quickly determine whether the proposal will be viable for rejection sampling. If the bound is seen to be large, the proposal may be refined by altering the partition or considering a different majorizer. Several specific choices of majorizer are considered by @VWS2025 and will be reviewed in the present document. [@sec-vws-constant] discusses the use of a constant function. A linear function is discussed in @sec-vws-linear.

## Constant Majorizer {#sec-vws-constant}

**TBD: Make this only about the method. Code will be elsewhere**

`RealConstRegion` is a subclass of `Region` for a particular setting where operations can be coded in a relatively problem-agnostic way. Suppose $\Omega = (a,b]$ is an interval whose endpoints may or may not be finite. Furthermore, suppose decomposition \eqref{eqn:weighted-target} is selected so that $w(x)$ is finite on each $\mathcal{D}_j$ and the constant $\overline{w}_j = \sup_{x \in \mathcal{D}_j} w(x)$ can serve as the majorizing function of $w$. Furthermore, let the minorizer for $w$ be the constant $\underline{w}_j = \inf_{x \in \mathcal{D}_j} w(x)$. Here we obtain component densities
$g_j(x) = g(x) \ind(x \in \mathcal{D}_j) / \Prob(T \in \mathcal{D}_j)$
along with the quantities
$\overline{\xi}_j = \overline{w}_j \Prob(T \in \mathcal{D}_j)$ and
$\underline{\xi}_j = \underline{w}_j \Prob(T \in \mathcal{D}_j)$.

Several components are needed to construct a object of class `RealConstRegion`: scalars `a` and `b` define the support, a weight function `w`, and an object that provides the necessary operations for base distribution $g$. 

```{r}
#| eval: false
#| prompt: true
region = RealConstRegion$new(a, b, w, g)
```

The argument `w` is a standard R function, but is expected to have two arguments: the first argument is the input to the function and the second argument `log` indicates whether the result should be returned on the log-scale (`log = TRUE`) or the original scale (`log = FALSE`).

```{r}
#| eval: false
#| prompt: true
w = function(x, log = TRUE) { ... }
```

For the argument `g`, the `vws` package provides a `univariate_helper` function that wraps these operations together in an `S3` object. Here is an example with $g$ as the $\text{N}(\mu, \sigma^2)$ distribution.

```{r}
mu = 0
sigma = 1

g = univariate_helper(
	d = function(x, log = FALSE) {
		# Density function with mean and sd fixed to mu and sigma
		dnorm(x, mean = mu, sd = sigma, log = log)
	},
	p = function(q, lower.tail = TRUE, log.p = FALSE) {
		# CDF function with mean and sd fixed to mu and sigma
		pnorm(q, mean = mu, sd = sigma, lower.tail = lower.tail, log.p = log.p)
	},
	q = function(p, lower.tail = TRUE, log.p = FALSE) {
		# Quantile function with mean and sd fixed to mu and sigma
		qnorm(p, mean = mu, sd = sigma, lower.tail = lower.tail, log.p = log.p)
	},
	s = function(x) {
		# Indicator of whether x is in the support of this distribution.
		is.numeric(x)
	}
)
```

Because the $\text{N}(\mu, \sigma^2)$ distribution is used as a
`univariate_helper` in `vws` package demonstrations, the following function is
provided as a shortcut to return the same structure as the call above.

```{r}
g = normal_helper(mu, sigma)
```

For a similar setting with an integer-valued support, the subclass
`IntConstRegion` of `RealConstRegion` may be considered. Usage
of `IntConstRegion` is similar to `RealConstRegion`, with some
implementation details customized to the integer case. In this setting, `g`
should be a `univariate_helper` based on an integer-valued distribution.

```{r}
#| eval: false
#| prompt: true
g = poisson_helper(lambda = 10)  ## A predefined helper for Poisson(lambda)
region = IntConstRegion$new(a, b, w, g)
```

A natural choice to partition a univariate $\Omega = (a,b]$ is to break it into intervals defined by knots $\alpha_0 < \cdots < \alpha_N$, with $\alpha_0 \equiv a$ and $\alpha_N \equiv b$ fixed. For a univariate support and a constant majorizer, the baseline strategy of `bifurcate` in the `RealConstRegion` class is to replace $\mathcal{D}_\ell = (\alpha_{\ell-1}, \alpha_{\ell}]$ with $\mathcal{D}_\ell^{(1)} = (\alpha_{\ell-1}, \alpha_{\ell^*}]$ and $\mathcal{D}_\ell^{(2)} = (\alpha_{\ell^*}, \alpha_\ell]$, where
<!-- -->
\begin{align*}
\alpha_{\ell^*} =
\begin{cases}
0 & \text{if $\alpha_{\ell-1} = -\infty$ and $\alpha_\ell = \infty$}, \\
\alpha_\ell - |\alpha_\ell| - 1 & \text{if $\alpha_{\ell-1} = -\infty$ and $\alpha_\ell < \infty$}, \\
\alpha_{\ell-1} + |\alpha_{\ell-1}| + 1 & \text{if $\alpha_{\ell-1} > -\infty$ and $\alpha_\ell = \infty$}, \\
(\alpha_{\ell-1} + \alpha_\ell) / 2 & \text{otherwise}.
\end{cases}
\end{align*}
<!-- -->
Here, `is_bifurcatable` is always taken to be `TRUE`. When the support is integer-valued, `RealConstRegion` instead considers
<!-- -->
\begin{align*}
\alpha_{\ell^*} =
\begin{cases}
0 & \text{if $\alpha_{\ell-1} = -\infty$ and $\alpha_\ell = \infty$}, \\
\alpha_\ell - |\alpha_\ell| - 1 & \text{if $\alpha_{\ell-1} = -\infty$ and $\alpha_\ell < \infty$}, \\
\alpha_{\ell-1} + |\alpha_{\ell-1}| + 1 & \text{if $\alpha_{\ell-1} > -\infty$ and $\alpha_\ell = \infty$}, \\
\lceil (\alpha_{\ell-1} + \alpha_\ell) / 2 \rceil & \text{otherwise}.
\end{cases}
\end{align*}
<!-- -->
The function `is_bifurcatable` returns `FALSE` for regions which contain no integers.

The `IntConstRegion` and `RealConstRegion` classes have an `optimize` method to compute the constants $\overline{w}_j$ and $\underline{w}_j$ numerically. 

```{r}
#| eval: false
#| prompt: true
region$optimize(maximize = TRUE, log = TRUE)
```

The arguments `maximize` and `log` are both indicators: optimization is carried out as a maximization if `maximize = TRUE` and a minimization otherwise; the optimized value is returned on the log-scale if `log = TRUE` and is returned on the original scale otherwise. Numerical optimization is convenient, but can be wasteful if the function $w$ can be maximized and/or minimized in closed-form. For such cases, the user may create a subclass of `IntConstRegion` or `RealConstRegion` and override the `optimize` method. An example of this is given in [@sec-ln-norm-const-custom].

## Linear Majorizer {#sec-vws-linear}

**TBD**: write about linear majorizer

## Knot Selection {#sec-vws-knots}

**TBD**

- Our rule of thumb (and greedy option)
- At specified knots


The `refine` function refines a given proposal, which is based on partition $\mathcal{D}_1, \ldots, \mathcal{D}_{N}$, by sequentially selecting and bifurcating regions $N'$ times to obtain a new partition $\mathcal{D}_1^*, \ldots, \mathcal{D}_{N + N'}^*$. The following rule of thumb seeks to reduce \eqref{eqn:bound}. Let
<!-- -->
\begin{align}
\rho_1 = \frac{
\overline{\xi}_1 - \underline{\xi}_1
}{
\sum_{j=1}^N \overline{\xi}_j
},
\quad \ldots, \quad
\rho_N = \frac{
\overline{\xi}_N - \underline{\xi}_N
}{
\sum_{j=1}^N \overline{\xi}_j
}
\label{eqn:bound-components}
\end{align}
<!-- -->
be the contribution of each region to \eqref{eqn:bound} when there are $N$ regions. We draw index $\ell$ from $(1, \ldots, N)$ with probabilities proportional to $\rho_1, \ldots, \rho_N$, then bifurcate region $\ell$ into regions $\mathcal{D}_\ell^{(1)}$ and $\mathcal{D}_\ell^{(2)}$. There may be a number of ways to define bifurcation when $\Omega$ is a multivariate set. For a given subclass of `Region`, the bifurcation approach is to be implemented in the `bifurcate` method. Additionally, each subclass of `Region` should implement the `is_bifurcatable` method which returns `FALSE` if a `Region` object should not be further bifurcated; otherwise it returns `TRUE`.

In the following example, a proposal `h_init` is refined `N = 10` times
to yield an improved proposal `h`.

```{R}
#| eval: false
#| prompt: true
h_init = FMMProposal$new(regions)
out = refine(h_init, N = 10)
h = out$h
```

In addition to the element `h` in the return value which represents the refined
proposal, the element `log_bdd_hist` contains a vector with values
<!-- -->
\begin{align*}
\log\left\{
1 - \frac{\sum_{j=1}^{N+t} \underline{\xi}_j^{(t)}}{\sum_{j=1}^{N+t} \overline{\xi}_j^{(t)}}
\right\}
\end{align*}
<!-- -->
computed at steps $t = 0, 1, \ldots, N'$ of the refinement process. Here, $\overline{\xi}_j^{(t)}$ and $\underline{\xi}_j^{(t)}$ respectively represent $\overline{\xi}_j$ and $\underline{\xi}_j$ at step $t$. Effectiveness of a call to `refine` can be evaluated by examining `log_bdd_hist`.

```{r}
#| eval: false
#| prompt: true
step = seq_along(out$log_bdd_hist) - 1  ## Make sequence 0, 1, ..., N
bdd = exp(out$log_bdd_hist)             ## Exponentiate to probability scale
plot(step, bdd, type = "l")
```

If the bound can be reduced to a sufficiently small probability, the user can be assured that the proportion of rejections will be relatively small during sampling. Note that the same call to `refine` may result in different `h` and `log_bdd_hist` outputs due to randomness in the refinement method.

# Preliminaries {#sec-prelim}

## Programming Model

**TBD**: Write samplers in C++ and expose them in R via Rcpp. Show a minimal
example of such a function here. Maybe mention that the first working example
is coming up in @sec-vmf or another example.

**TBD:** Emphasize that API is in the `vws` namespace.

## Lambdas in C++

**TBD**: Recall lambdas in general

**TBD:** Mention density, cdf, quantile function definitions and numerical tools via fntl.

## Log-Scale Arithmetic

**TBD:** Explain that computations are kept on log-scale in the package and why we do it.

## Custom Optimization {#sec-user-opt}

**TBD**

- Mention that we use a numerical method by default
- R version
- C++ version

# Overview of Package {#sec-overview}

The `vws` package aims to support the methodology which was described in the previous section. The present section will describe tools in the package which can be used to formulate a problem, construct a proposal, and generate samples.

::: {.callout-caution title="TBD"}
Misc

- How about the name `d_g` instead of `d_base`?
- We'll want to show some examples where we override `optimize` and maybe the
  bifurcate functions. Consider pointing to them somewhere in this section.
- Readers might want to check out one of the first / easiest examples (name
  one) to see the basic usage pattern, then jump back up here to see the
  components described in more detail. May want to say this before we start
  going into any detail.
:::

Use of the package focuses on two `R6` classes. The `FMMProposal` class represents finite mixture \eqref{eqn:fmm-proposal} and encapsulates operations needed for rejection sampling. The `Region` class represents region $\mathcal{D}_j$ and the operations that must be supported on it for VWS; i.e., all problem-specific logic is coded within a `Region`. An `FMMProposal` object is created from a list of one or more `Region` objects that represent the partition $\mathcal{D}_1, \ldots, \mathcal{D}_N$ of $\Omega$.

The `rejection` function takes an object `h` of class `FMMProposal` and carries out
the rejection sampling algorithm to obtain `n` draws. The return value of `rejection` is a list where each element represents an accepted draw. Optional arguments may be passed
through a `rejection_control` (S3) object, including: a count of rejections to be tolerated before halting, and whether to return additional information about rejections which occurred during sampling. The following display gives a typical workflow for sampling.

```{R}
#| eval: false
#| prompt: true
regions = list(region1, region2)
h = FMMProposal$new(regions)
ctrl = rejection_control(max_rejects = 5000)
rejection(h, n = 1000, control = ctrl)
```

```{r}
#| include: false
# If the interface has changed, catch it and bail out
actual = names(formals(rejection_control))
expected = c("max_rejects", "report", "extra_outputs", "action_incomplete")
base::setequal(actual, expected) |> stopifnot()
```

Here, `region1` and `region2` are objects whose class is a subclass of `Region`. The `Region` class itself is abstract and defines necessary operations. Further details are given in Sections [-@sec-cpp-api-region], [-@sec-cpp-api-realconstregion], and [-@sec-cpp-api-intconstregion].

Before sampling, the `refine` function can be used to refine a given
`FMMProposal` object by partitioning a given set of regions into a finer set.
The can make it a better approximation of the target distribution. Details are
given in Section [-@sec-cpp-api-proposal].

@fig-software-design displays a diagram of the high-level design just described. @sec-cpp-api walks through the API components in depth. The user may also consult manual entries (e.g., `?Region`) for details such as arguments to methods and their default values.

![Design of `vws` package.](software-design.pdf){#fig-software-design}

## Basic Usage {#sec-overview-usage}

**TBD:** Basic usage and functions here. Maybe not a working example here, but
refer the reader to one of the complete working examples that comes up later.
Also give a reference to the API section.

## Implementing Samplers via Regions {#sec-overview-regions}

**TBD:** Discuss regions here at a high level. This is the most important part of the API because it is how users implement problems. They can use `RealConstRegion` or `IntConstRegion` for univariate problems with constant majorizers. They can customize the optimization in these from the default numerical method. They can also subclass the abstract `Region` class to implement other support types.

For targets where the support is not univariate, or where the desired majorizer is something other than a constant, the user may create a subclass `Region` to implement VWS. This new class must implement the methods in Table `?` using `R6`. Here is a skeleton of a such a subclass named `CustomRegion` to illustrate this process. Complete implementations of such subclasses are given in Sections [-@sec-ln-norm-linear] and [-@sec-vws-linear].

## Knot Selection {#sec-overview-knots}

**TBD**

- Our rule of thumb (and greedy option)
- At specified knots


# C++ API {#sec-cpp-api}

This section documents functions, classes, and other components in the C++ API. 

## Typedefs {#sec-cpp-api-typedefs}

We define a shorthand for the maximum value of an unsigned integer.

```{cpp}
unsigned int uint_max = std::numeric_limits<unsigned int>::max();
```

The following typedef represents an indicator function. 

```{cpp}
typedef std::function<bool(double x)> indicator;
```

The following typedef represents a weight function. 

```{cpp}
typedef std::function<double(double x, bool log)> weight_dfd;
```

Here, `x` is the argument of the weight function and `log` determines if the result is returned on the log-scale.

The following typedef represents a function that optimizes (i.e., maximizes or
minimizes) a weight function on a given interval.

```{cpp}
typedef std::function<double(
	const weight_dfd& w,  // <1>
	double lo,            // <2>
	double hi,            // <3>
	bool log              // <4>
)> optimizer;
```
1. A weight function.
2. Lower bound of the interval; may be `R_NegInf`.
3. Upper bound of the interval; may be `R_PosInf`.
4. Logical; `log = true` specifies that the result should be the optimal value
   $\log w(x^*)$, given on the log-scale. Otherwise, the result should be the
   optimal value $w(x^*)$ on the original scale.

The following enum specifies actions for when error conditions are encountered.

```{cpp}
enum class error_action {
	STOP,
	WARNING,
	MESSAGE,
	NONE
};
```
1. Throw an exception.
2. Emit a warning and proceed.
3. Print a message and proceed.
4. Do not take any of the above actions and proceed.

**TBD:** should we try to use `fntl::error_action` instead?

**TBD** Can we pass `optimize_hybrid` to `RealConstRegion` as the default and
clean up that part of the code?

## Finite Mixture Proposal {#sec-cpp-api-proposal}

The class `FMMProposal` represents a VWS proposal. 

### Class Definition {.unnumbered .unlisted}

`FMMProposal` has two template arguments: `T` is the data type for the
underlying distribution (e.g., `T = double` for univariate and real-valued) and
`R` is the type of the regions of which the proposal will be composed.

```{cpp}
template <class T, class R>
class FMMProposal {
	...
}
```

### Constructor {.unnumbered .unlisted}

There is a single constructor that take a vector of regions of type `R`. There
must be at least one region in the vector, and these regions are expected to be
a partition of the support $\Omega$.

```{cpp}
FMMProposal(const std::vector<R>& regions);
```

### Distribution Methods {.unnumbered .unlisted}

The following functions make use of the proposal as a distribution. They are
especially utilized in rejection sampling.

```{cpp}
std::vector<T> r(unsigned int n = 1) const;                                           // <1>
std::pair<std::vector<T>, std::vector<unsigned int>> r_ext(unsigned int n = 1) const; // <2>
double d(const T& x, bool normalize = true, bool log = false) const;                  // <3>
double w_major(const T& x, bool log = true) const;                                    // <4>
double d_target_unnorm(const T& x, bool log = true) const;                            // <5>
```
1. Draw $n$ variates of type `T` from the proposal.
2. Draw $n$ variates of type `T` from the proposal and retain the indices of
the regions used in each draw. The results are returned as an STL pair whose
first element is the vector of draws and second element is the vector of
indices.
3. Evaluate the density $h$ on the given $x$. If `normalize = false`, $h_0(x)$
is computed; otherwise $h(x)$ is computed. If `log = true`, results are given
on the log-scale.
4. Evaluate the majorized weight function $\overline{w}(x)$. If `log = true`,
results are returned on the log-scale.
5. Evaluate the unnormalized target $f_0(x) = w(x) g(x)$. If `log = true`, the
value on the log-scale is returned.

### Accessors {.unnumbered .unlisted}

The following accessors are provided.

```{cpp}
Rcpp::NumericVector xi_upper(bool log = true) const;                  // <1>
Rcpp::NumericVector xi_lower(bool log = true) const;                  // <2>
Rcpp::LogicalVector bifurcatable() const;                             // <3>
Rcpp::NumericVector pi(bool log = false) const;                       // <4>
Rcpp::NumericVector rejection_bound_regions(bool log = false) const;  // <5>
double rejection_bound(bool log = false) const;                       // <6>
double nc(bool log = false) const;                                    // <7>
unsigned int size() const;                                            // <8>
```
1. Get the constants $\overline{\xi}_1, \ldots, \overline{\xi}_N$.
2. Get the constants $\underline{\xi}_1, \ldots, \underline{\xi}_N$.
3. Get a vector of $N$ logical values indicating whether the corresponding
regions can be bifurcated. For example, when the support `T` is `int`, a
region $[a,b]$ containing one integer should not be bifurcated because one of
the two resulting regions will not contain any points of the support.
4. Get the mixing proportions $\pi_1, \ldots, \pi_N$.
5. Get the contributions $\rho_1, \ldots, \rho_N$ to bound \eqref{eqn:bound}
for each region.
6. Get the overall rejection bound \eqref{eqn:bound}.
7. Get the normalizing constant $\psi_N$
8. Get the number of regions $N$.

Methods above with the a `log` argument return values on the log-scale when
`log = true`.

### Iterator Methods {.unnumbered .unlisted}

The following methods can be used to get (read-only) iterators to internal data structures. These can be more efficient than the accessors above because they
do not make a copy of the data.

```{cpp}
std::set<R>::const_iterator regions_begin() const;               // <1>
std::set<R>::const_iterator regions_end() const;
Rcpp::NumericVector::const_iterator log_xi_upper_begin() const;  // <2>
Rcpp::NumericVector::const_iterator log_xi_upper_end() const;
Rcpp::NumericVector::const_iterator log_xi_lower_begin() const;  // <3>
Rcpp::NumericVector::const_iterator log_xi_lower_end() const;
Rcpp::LogicalVector::const_iterator bifurcatable_begin() const;  // <4>
Rcpp::LogicalVector::const_iterator bifurcatable_end() const;
```
1. The start and end of the set of regions (of type `R`) in the proposal.
2. The start and end of the vector
$\overline{\xi}_1, \ldots, \overline{\xi}_N$.
3. The start and end of the vector
$\underline{\xi}_1, \ldots, \underline{\xi}_N$.
4. The start and end of the vector of bifurcatable indicators.

### Methods to Refine the Proposal {.unnumbered .unlisted}

Two functions are provided to refine the proposal from
$\mathscr{D}_1, \ldots, \mathscr{D}_N$ into a finer partition.

```{cpp}
Rcpp::NumericVector refine(const std::vector<T>& knots);    // <1>
Rcpp::NumericVector refine(unsigned int N, double tol = 0,  // <2>
	bool greedy = false, unsigned int report = uint_max);
```
1. Partition at the given vector of knots.
2. Refine the proposal using rule of thumb for sequential knot selection
from @VWS2025. Refining will halt when \eqref{eqn:bound} reduces below `tol`;
this has an effect when `tol` is positive. Otherwise, `N` is the maximum number
of partition steps taken. If `greedy = true`, the region with the largest
$\rho_\ell$ is always selected for partitioning; otherwise, regions are
selected with probabilities proportional to $\rho_1, \ldots, \rho_N$. The
argument `report` represents the period that progress is written to the
console.

The `seq` function is provided to generate equally-spaced knots for univariate
real-valued intervals.

```{cpp}
std::vector<double> seq(double lo, double hi, unsigned int N, bool endpoints = false);
```

**TBD:** Should the first refine function take a vector of ints for `IntConstRegion` regions?

### Summary Methods {.unnumbered .unlisted}

Several methods are provided to summarize the regions in the proposal.

```{cpp}
Rcpp::DataFrame summary() const;       // <1>
void print(unsigned int n = 5) const;  // <2>
```
1. Get a data frame with the summary.
1. Print summary to the console.

## Region Base Class {#sec-cpp-api-region}

`Region` is an abstract base class whose interface represents the
problem-specific logic that must be coded to implement VWS. Users create a
subclass of this method to construct a proposal for a given problem. However,
for the most common application of VWS - univariate support with a constant
majorizer - users may start with a specialized subclass. See
Sections [-@sec-cpp-api-realconstregion] and [-@sec-cpp-api-intconstregion].

**TBD**: mention that bifurcated objects inherit values of the original such
as `w` and the optimization functions.

### Class Definition {.unnumbered .unlisted}

The class has one template argument `T`, which is the data type for the
underlying distribution.

```{cpp}
template <class T>
class Region { ... }
```

### Public Methods {.unnumbered .unlisted}

The interface consists of the following public methods. These are abstract and
must be implemented in a subclass.

```{cpp}
virtual double d_base(const T& x, bool log = false) const = 0; // <1>
virtual std::vector<T> r(unsigned int n) const = 0;            // <2>
virtual bool s(const T& x) const = 0;                          // <3>
virtual double w(const T& x, bool log = true) const = 0;       // <4>
virtual double w_major(const T& x, bool log = true) const = 0; // <5>
virtual bool is_bifurcatable() const = 0;                      // <6>
virtual double xi_upper(bool log = true) const = 0;        // <7>
virtual double xi_lower(bool log = true) const = 0;        // <8>
virtual std::string description() const = 0;                   // <9>
```
1. Evaluate the density function $g$ of the base distribution.
2. Generate a vector of $n$ draws from $g_j$ specific to this region.
3. Indicator of whether $x$ is in the support for $g_j$ specific to this region.
4. The weight function $w$.
5. Majorized weight function $\overline{w}_j$ for this region.
6. Indicator of whether this region is bifurcatable into two smaller regions.
This is used when refining a proposal; see Section TBD. One reason that a
region should not be bifurcated is when one of the resulting regions will not
have any points of support.
7. The quantity $\overline{\xi}_j$ for this region.
8. The quantity $\underline{\xi}_j$ for this region.
9. A string that describes this region.

The argument `log = true` in the methods above requests values to be returned
on the log-scale.

## Region on Real-Valued Support with Constant Majorizer {#sec-cpp-api-realconstregion}

This is a subclass of `Region`, defined in @sec-cpp-api-region, specifically for
univariate problems with continuous support where
$\overline{w}(x) = \sum_{j=1}^N \overline{w}_j \ind(x \in \mathscr{D}_j)$ is
constructed from constants $\overline{w}_1, \ldots, \overline{w}_N$. Similarly,
a minorizer
$\underline{w}(x) = \sum_{j=1}^N \underline{w}_j \ind(x \in \mathscr{D}_j)$
is constructed from constants $\underline{w}_1, \ldots, \underline{w}_N$.
The $\overline{w}_j$ and $\underline{w}_j$ are obtained using numerical
optimization; however, if a closed-form solution is known, the user may
create a subclass and override the optimization method.

### Constructors {.unnumbered .unlisted}

In addition to the methods defined in `Region`, we have the following
constructors.

```{cpp}
RealConstRegion(
	double a,                                 // <1>
	double b,                                 // <2>
	const weight_dfd& w,                      // <3>
	const UnivariateHelper& helper,           // <4>
    const optimizer& maxopt = maxopt_default, // <5>
    const optimizer& minopt = minopt_default  // <6>
);

RealConstRegion(
	double a,                                 // <1>
	const weight_dfd& w,                      // <3>
	const UnivariateHelper& helper            // <4>
    const optimizer& maxopt = maxopt_default, // <5>
    const optimizer& minopt = minopt_default  // <6>
);
```
1. Lower limit of interval that defines this region.
2. Upper limit of interval that defines this region.
3. Weight function $w$ for the target distribution.
4. A container with operations of the base distribution $g$.
5. A function of type `optimizer` that maximizes `w` on the given region.
5. A function of type `optimizer` that minimizes `w` on the given region.

The first constructor creates a region based on the interval $(a,b]$; the
second creates a region based on the singleton set $\{a\}$, which is intended
primarily for internal use.

The default optimizers, `maxopt_default` and `minopt_default`, use the hybrid
numerical optimization method in @sec-cpp-api-opt to optimize `w`.

### Methods {.unnumbered .unlisted}

The `optimize` method maximizes or minimizes the weight function $w$ over the
given region. The the optimized value of $w$ is returned. If `maximize = true`
do maximization; otherwise do minimization. If `log = true`, return value on
the log-scale. Otherwise, return it on the original scale.

```{cpp}
double optimize(bool maximize = true, bool log = true) const;
```

**TBD:** Do we still have the `optimize` method? If so, do we need it?

The `midpoint` method returns a point between endpoints $a$ and $b$ of the
region. If $a$ and $b$ are both finite, return the standard midpoint. If both
are infinite, zero is returned. If only $a$ is finite, return a larger point in
the support. If only $b$ is finite, return a smaller point in the support.

```{cpp}
double midpoint() const;
```

The `bifurcate` method returns two disjoint regions whose union is the current
region. The result is given as an STL pair. The first version bifurcates at the
midpoint of the current region, determined by the `midpoint` method. The second
version partitions at the given $x$.

```{cpp}
std::pair<RealConstRegion,RealConstRegion> bifurcate() const;
std::pair<RealConstRegion,RealConstRegion> bifurcate(const double& x) const;
```

The `singleton` method returns a singleton interval $(x, x]$, using the current
object's weight function, base distribution, etc.

```{cpp}
RealConstRegion singleton(const double& x) const;
```

The following methods determine an ordering of the current region and an
another region specified as argument `x`. Region $(a_1, b_1]$ is considered
"less than" $(a_2, b_2]$ if $b_1 < a_2$. The regions are considered equal if
$a_1 = a_2$ and $b_1 = b_2$. Note that other elements such as $w$ are $g$ are
not explicitly checked, and are assumed to be the same.

```{cpp}
bool operator<(const RealConstRegion& x) const;
bool operator==(const RealConstRegion& x) const;
```

The following method assigns the current region to be equal to the argument `x`.

```{cpp}
const RealConstRegion& operator=(const RealConstRegion& x);
```

## Region on Integer-Valued Support with Constant Majorizer  {#sec-cpp-api-intconstregion}

**TBD**: do we still need this?

## Univariate Helper {#sec-cpp-api-helper}

`UnivariateHelper` is a class which is intended for use with `RealConstRegion`. It encapsulates several operations needed from the base distribution $g$. These operations are specified as lambdas in the constructor.


```{cpp}
UnivariateHelper(
	const fntl::density& d,  // <1>
	const fntl::cdf& p,      // <2>
	const fntl::quantile& q, // <3>
	const supp& s            // <4>
);
```
1. A function to evaluate density $g$.
2. A function to evaluate the CDF $G$.
3. A function to evaluate the quantile function $G^{-}$.
4. An indicator function that returns $1$ if its argument is in the support of
$g$; otherwise, it returns $0$.

The following methods on `UnivariateHelper` utilize the lambdas specified above.

```{cpp}
double d(double x, bool log = false) const;                     // <1>
double p(double q, bool lower = true, bool log = false) const;  // <2>
double q(double p, bool lower = true, bool log = false) const;  // <3>
bool s(double x) const;                                         // <4>
```
1. Evaluate the density function at argument $x$. Result is on the log-scale if
`log = true`.
2. Evaluate the cumulative distribution function (CDF) at argument $q$. Result
is on the log-scale if `log = true`. Result represents $P(X \leq q)$ if
`lower = true` and $P(X > q)$ otherwise.
3. Evaluate the quantile function at argument $p$. Assume $p$ is specified on
the log-scale if `log = true`. Request $p$ quantile if `lower = true` and
$1-p$ quantile otherwise.
4. Indicator of whether argument $x$ is in the support of the distribution.


## Rejection Sampling {#sec-cpp-api-rejection}

The following functions carry out rejection sampling using a VWS proposal
described in @sec-cpp-api-proposal.

```{cpp}
template <typename T, typename R>
inline rejection_result<T> rejection(
	const FMMProposal<T,R>& h,         // <1>
	unsigned int n,                    // <2>
	const rejection_args& args         // <3>
);

template <typename T, typename R>
inline rejection_result<T> rejection(
	const FMMProposal<T,R>& h,         // <1>
	unsigned int n                     // <2>
);
```
1. An `FMMProposal` object to use as the proposal.
2. The number of desired draws.
3. Additional arguments for rejection sampling. Default values are assumed in
the second form.

Template arguments `T` and `R` correspond to the given proposal `h` and are
described in @sec-cpp-api-proposal. Additional arguments are provided via the
following struct.

```{cpp}
struct rejection_args
{
	unsigned int max_rejects = std::numeric_limits<unsigned int>::max(); // <1>
	unsigned int report = std::numeric_limits<unsigned int>::max();      // <2>
	double ratio_ub = std::exp(1e-5);                                    // <3>
	error_action action = error_action::STOP;                            // <4>

	rejection_args() { };                                                // <5>
	rejection_args(SEXP obj);                                            // <6>
	operator SEXP() const;                                               // <7>
};
```
1. Maximum number of rejections to tolerate overall (among all $n$ attempted
draws) before bailing out.
2. Determines period at which progress is logged to the console.
3. Upper bound for the ratio $f_0(x) / h_0(x)$. The ratio may be slightly
larger than 1 due to numerical precision, but an error is thrown if it is
larger than this value.
4. The action to take if `max_rejects` rejections is exceeded. See
below for possible values.
5. Constructor that takes no arguments.
6. Convert an `Rcpp::List` to a `rejection_args` struct.
7. Return a `Rcpp::List` from a `rejection_args` struct.

The return value of `rejection` is a struct of the following type.

```{cpp}
template <typename T>
struct rejection_result
{
	std::vector<T> draws;               // <1>
	std::vector<unsigned int> rejects;  // <2>

	operator SEXP() const;              // <3>
};
```
1. Vector of draws.
2. Vector of rejection counts; the $i$th element represents number of
rejections observed before accepting the $i$th draw.
3. Return a `Rcpp::List` from a `rejection_args` struct.

If `action != error_action::STOP` in `rejection_args`, the sampler can halt
before all $n$ desired variates are drawn. In this case, the `draws` and
`rejects` vectors will have lengths shorter than $n$.

**TBD** here is `error_action`.


## Optimization on an Interval {#sec-cpp-api-opt}

A hybrid optimization method for univariate functions $f(x) : [a,b] \rightarrow \mathbb{R}$ with bounds $x \in [a,b]$ that may be infinite. Uses Brent's method if both bounds are finite and BFGS otherwise. In the latter case, the bounds are enforced via a transformation.

```{cpp}
optimize_hybrid_result optimize_hybrid(
	const fntl::dfd& f,       // <1>
    double init,              // <2>
	double lower,             // <3>
	double upper,             // <4>
	bool maximize,            // <5>
	unsigned maxiter = 100000 // <6>
);
```
1. Objective function.
2. Initial value used with BFGS.
3. Lower bound.
4. Upper bound.
5. Logical; if `true`, optimization will be a maximization. Otherwise it is a minimization.
6. Maximum number of iterations.

The result is a `optimize_hybrid_result` struct which is defined as follows.

```{cpp}
struct optimize_hybrid_result {
	double par;            // <1>
	double value;          // <2>
	std::string method;    // <3>
	int status;            // <4>

	operator SEXP() const; // <5>
};
```
1. Final value of the optimization variable $x$.
2. Final value of the objective function $f(x)$.
3. Description of the method used to find the result; see below.
4. Corresponds to a code from BFGS if it is used as `method`; otherwise zero.
5. Return an `Rcpp::List` from a `optimize_hybrid_result` struct.

The `method` field can take on the following values:

- "Brent": Brent optimization method was used.
- "BFGS": BFGS method was used.
- "Lower Limit Inf": For a maximization problem, the lower limit was taken
  as `par` because it had value `inf`.
- "Upper Limit Inf": For a maximization problem, the upper limit was taken
  as `par` because it had value `inf`.
- "Lower Limit NegInf": For a minimization problem, the lower limit was
  taken as `par` because it had value `-inf`.
- "Upper Limit NegInf": For a minimization problem, the upper limit was
  taken as `par` because it had value `-inf`.
- "Max at Lower Limit": numerical maximization was used, but a larger value
  was found at the lower limit.
- "Max at Upper Limit": numerical maximization was used, but a larger value
  was found at the upper limit.
- "Min at Lower Limit": numerical minimization was used, but a smaller value
  was found at the lower limit.
- "Min at Upper Limit": numerical minimization was used, but a smaller value
  was found at the upper limit.


## Log-Scale Arithmetic {#sec-cpp-api-logscale}

Calculations in the package are carried out on the log-scale, where possible,
to avoid issues from floating point numbers with very small or very large
magnitudes. Users may want to follow this convention when implementing their
own sampling problems. Several included functions help to avoid explicit
exponentiation and may be helpful for this purpose.

The following computes the scalar $f(x) = log\{ \sum_{i=1}^n \exp(x_i) \}$ from a vector $x \in \mathbb{R}^n$.

```{cpp}
double log_sum_exp(const Rcpp::NumericVector& x);
```

The following compute addition on the log scale: $\log(e^x + e^y)$. The first
form takes scalar $x$ and $y$. The second and third forms take
$x, y \in \mathbb{R}^n$ and produce an $n$-dimensional vector.

```{cpp}
double log_add2_exp(double x, double y);
std::vector<double> log_add2_exp(const std::vector<double>& x, const std::vector<double>& y);
Rcpp::NumericVector log_add2_exp(const Rcpp::NumericVector& x, const Rcpp::NumericVector& y);
```

The following carry out subtraction on the log scale: $\log(e^x - e^y)$. The
first form takes scalar $x$ and $y$. The second and third forms take
$x, y \in \mathbb{R}^n$ and produce an $n$-dimensional vector. Here, elements of $x$ smaller than $y$ result in `NaN`.

```{cpp}
double log_sub2_exp(double x, double y);
std::vector<double> log_sub2_exp(const std::vector<double>& x, const std::vector<double>& y);
Rcpp::NumericVector log_sub2_exp(const Rcpp::NumericVector& x, const Rcpp::NumericVector& y);
```

## Generating from a Discrete Distribution {#sec-cpp-api-discrete}

We make use of the Gumbel trick [e.g., @HuijbenEtAl2023] to draw from a discrete distribution with probabilities $p_1, \ldots, p_k$. This approach allows probabilities to be specified on the log-scale without the need to exponentiate or normalize them so that they sum to one. The Gumbel trick generates a draw $x$ from the desired discrete distribution via
<!-- -->
$$
X = \argmax \{ Z_1 + \log p_1, \ldots, Z_k + \log p_k \},
\quad Z_1, \ldots, Z_k \iid \text{Gumbel}(0,1),
$$
<!-- -->
where $\text{Gumbel}(0,1)$ is a standard Gumbel distribution with density
$f(x) = e^{-(x + e^{x})}$. A benefit of this method is that the probabilities
can be given on the log-scale and do not necessarily need to be exponentiated.

The following functions generate a draw of $X$. The first form generates a
single variate and the second form generates a sample of size $n$.

```{cpp}
unsigned int r_categ(
	const Rcpp::NumericVector& p,  // <2>
	bool log = false,              // <3>
	bool one_based = false         // <4>
);
Rcpp::IntegerVector r_categ(
	unsigned int n,                // <1>
	const Rcpp::NumericVector& p,  // <2>
	bool log = false,              // <3>
	bool one_based = false         // <4>
);
```
1. Desired sample size.
2. Vector of probabilities $p_1, \ldots, p_k$.
3. Logical; if `true`, indicates that argument `p` should be interpreted as
$\log p_1, \ldots, \log p_k$. Otherwise, it is interpreted as
$p_1, \ldots, p_k$ on the original scale.
4. Logical; if `true`, support is assumed to be $1, \ldots, k$, where $k$ is
length of the given `p`. Otherwise it is assumed to be $0, \ldots, k-1$. The
former is useful to generate indices in C++ while the latter is useful for
indices in R.

The following functions are provided for the Gumbel distribution with location
parameter $\mu$ and scale $\sigma$. They provide density, CDF, quantile, and
variate generation, respectively.

```{cpp}
double d_gumbel(double x, double mu = 0, double sigma = 1,
	bool log = false);
double p_gumbel(double q, double mu = 0, double sigma = 1,
	bool lower = true, bool log = false);
double q_gumbel(double p, double mu = 0, double sigma = 1,
	bool lower = true, bool log = false);
double r_gumbel(double mu = 0, double sigma = 1);
```

The following vectorized versions operate on an independent and identically
distributed sample.

```{cpp}
Rcpp::NumericVector d_gumbel(const Rcpp::NumericVector& x, double mu = 0,
	double sigma = 1, bool log = false);
Rcpp::NumericVector p_gumbel(const Rcpp::NumericVector& q, double mu = 0,
	double sigma = 1, bool lower = true, bool log = false);
Rcpp::NumericVector q_gumbel(const Rcpp::NumericVector& p, double mu = 0,
	double sigma = 1, bool lower = true, bool log = false);
Rcpp::NumericVector r_gumbel(unsigned int n, double mu = 0, double sigma = 1);
```

# Example: Von Mises Fisher {#sec-vmf}

::: {.callout-caution title="TBD"}
Under construction. Both versions of the sampler are implemented, but writing
is needed.
:::

Suppose $X$ has density

\begin{align}
f(x) =
\frac{
(\kappa / 2)^{d/2 - 1} (1 - x^2)^{(d-3)/2} \exp(\kappa x)
}{
\sqrt{\pi} \cdot I_{d/2 - 1}(\kappa) \cdot \Gamma((d-1)/2)
} \cdot \mathbb{1}_{(-1,1)}(x).
\label{eqn:vmf-target}
\end{align}

Let us decompose $f$ into

\begin{align*}
f(x) \propto
\underbrace{(1 - x^2)^{(d-3)/2}}_{w(x)}
\underbrace{\exp(\kappa x) \cdot \mathbb{1}_{(-1,1)}(x)}_{g_0(x)},
\end{align*}

where $w$ is a nonnegative weight function and $g_0$ is proportional to density

\begin{align*}
g(x) = \frac{\kappa e^{\kappa x}}{e^\kappa - e^{-\kappa}} \cdot \mathbb{1}_{(-1,1)}(x).
\end{align*}

The CDF corresponding to $g$ is

\begin{align*}
G(x) = \frac{e^{\kappa x} - e^{-\kappa x}}{e^\kappa - e^{-\kappa}} \cdot,
\quad x \in (-1, 1)
\end{align*}

and the quantile function is

\begin{align*}
G^{-1}(\varphi) = \frac{1}{\kappa} \log\left[e^{\kappa a} + \varphi (e^{\kappa b} - e^{\kappa a}) \right], \quad \varphi \in [0,1].
\end{align*}


Check the manual entry for `Region` to see which methods need to be implemented.

```{r}
#| eval: false
#| prompt: true
?Region
```

The needed operations for the base and target distributions are defined in the
following files.

```{r}
#| prompt: true
source("../inst/examples/vmf/base.R")             # Functions for base dist'n
source("../inst/examples/vmf/target.R")           # Functions for target dist'n
source("../inst/examples/vmf/VMFLinearRegion.R")  # VMFLinearRegion class def'n
```

TBD: we have to truncate support to something within $[-1,1]$ when $d < 3$
because $w$ is not finite at the endpoints.

## Constant Majorizer with Numerical Optimization

::: {.callout-caution title="TBD"}
Under construction
:::

Let us consider an example C++ code making use of this framework. The following
declares a sampler in C++ and exposes an R interface function.

```{.cpp include="examples/vmf/vmf-v1.cpp" code-line-numbers="true"}
```

There are several points of interest to call out. (TBD: needs to be updated)

- Line 1 ensures that this code is linked with the `vws` and `fntl` packages.
  `fntl` is not used directly in this example, but is needed by `vws`.
- Line 2 includes the headers for C++ framework in `vws`.
- Line 3 includes the header for a "helper" class that encapsulates several
  functions of the $\text{Uniform}(a,b)$ distribution needed by the sampler:
  the density, CDF, quantile function, and an indicator function for the
  support.
- Lines 5-6 define a C++ function and export it for use in R.
- Lines 9-11 prepare a structure with arguments for rejection sampling. Notice
  that `rejection_args` (along with other `vws` classes and functions) are in
  the `vws` namespace.
- Lines 13-20 define the weight function using C++ lambda syntax.
- Lines 22-24 construct a specific type of `Region` and build an `FMMProposal`
  from it. Notice that there are two template arguments specified here: the
  first `double` specifies the type of the support and the second
  `RealConstRegion` specifies the type of `Region`.
- Line 26 refines the proposal `N-1` times so that there are `N` regions.
- Line 27 carries out rejection sampling with proposal `h`.
- Line 29-32 extracts the draws and vector rejection counts (where the `i`th
  element represents the number of rejections for the `i`-th draw) and returns
  them in an `Rcpp::List`.

We may call the exported R function as follows.

```{r}
Rcpp::sourceCpp("examples/vmf/vmf-v1.cpp")
sample(n = 10, kappa = 5, d = 4, N = 10)
```


Define base distribution and weight function.

```{r}
d = 2
kappa = 0.2

helper = vmf_base_helper(kappa)

w = function(x, log = FALSE) {
	out = (d - 3) / 2 * log(1 - x^2)
	if (log) { return(out) } else { return(exp(out)) }
}
```

```{r}
support = RealConstRegion$new(a = 1e-4 - 1, b = 1 - 1e-4, w = w, g = helper)
regions = list(support)
```

Refine the proposal.

```{r}
h_init = FMMProposal$new(regions)
refine_out = refine(h_init, N = 100, report = 20)
h = refine_out$h
```

Plot the rate of refinement improvement. (TBD: consider making this an object
that can quickly be plotted. But this might add a dependency if it's ggplot).

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Rate of refine improvement for VMF example with constant majorizer.
#| label: fig-vmf-const-refine

data.frame(bdd = exp(refine_out$log_bdd_hist)) %>%
	mutate(step = row_number() - 1) %>%
	ggplot() +
	geom_line(aes(x = step, y = bdd)) +
	scale_y_continuous(n.breaks = 10) +
	xlab("Step") +
	ylab("Bound") +
	theme_minimal()
```

Generate draws.

```{r}
ctrl = rejection_control(max_rejects = 10000, report = 5000)
out = rejection(h, n = 10000, control = ctrl)
x = unlist(out)
```

Plot the empirical distribution of the draws with the target density.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Empirical distribution of draws versus target for VMF example with
#|   constant majorizer.
#| label: fig-vmf-const-draws

data.frame(x = x) %>%
	ggplot() +
	geom_histogram(aes(x = x, y = after_stat(density)), col = "black",
		fill = NA, bins = 25) +
	geom_function(fun = d_target, args = list(kappa = kappa, d = d),
		lty = 2, xlim = c(1e-2 - 1, 1 - 1e-2)) +
	ylab("Density") +
	theme_minimal()
```

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Proposal versus target on the log-scale for VMF example with constant
#|   majorizer.
#| label: fig-vmf-const-proposal

log_h = function(x) { sapply(x, h$d, log = TRUE) }
log_f = function(x) { d_target(x, kappa = kappa, d = d, log = TRUE) }

ggplot() +
	geom_function(fun = log_f, col = "orange", lty = 1) +
	geom_function(fun = log_h, col = "black", lty = 2) +
	scale_x_continuous(limits = c(1e-2 - 1, 1 - 1e-2)) +
	xlab("x") +
	ylab("Density") +
	theme_minimal()
```

## Constant Majorizer with Custom Optimization


```{.cpp include="examples/vmf/vmf-v2.cpp" code-line-numbers="true"}
```

```{r}
Rcpp::sourceCpp("examples/vmfvmf/vmf-v2.cpp")
sample2(n = 10, kappa = 5, d = 4, N = 10)
```


## Linear Majorizer {#sec-vmf-linear}

For this region:

- $w$ is assumed to be $w(x) = (1 - x^2)^{(d - 3)/2}$
- $g$ is assumed to be proportional to $\exp(\kappa x)$
- majorized $w$ is assumed to be of the form $\exp(\beta_0 + \beta_1 x)$

Note that $\log(w(-1)) = \log(w(1)) = \infty$ with this choice when $d < 3$. A
workaround is to exclude the endpoints from the support.

```{r}
d = 2
kappa = 0.2
```

Create a single region of class `VMFLinearRegion`.

```{r}
support = VMFLinearRegion$new(a = 1e-4 - 1, b = 1 - 1e-4, kappa = kappa, d = d)
regions = list(support)
```

Refine the proposal.

```{r}
h_init = FMMProposal$new(regions)
refine_out = refine(h_init, N = 100, report = 20)
h = refine_out$h
```

Plot the rate of refinement improvement. Plot on the log-scale; the log-scale helps to see improvement in later steps.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Rate of refine improvement on the log-scale for VMF example with
#|   linear majorizer.
#| label: fig-vmf-linear-refine

data.frame(logbdd = refine_out$log_bdd_hist) %>%
	mutate(step = row_number() - 1) %>%
	ggplot() +
	geom_line(aes(x = step, y = logbdd)) +
	scale_y_continuous(n.breaks = 10) +
	xlab("Step") +
	ylab("Log of Bound") +
	theme_minimal()
```

Generate draws.
```{r}
control = rejection_control(max_rejects = 100, report = 5000)
out = rejection(h, n = 10000, control = control)
x = unlist(out)
```

Plot the empirical distribution of the draws with the target density.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Empirical distribution of draws versus target for VMF example with linear
#|   majorizer.
#| label: fig-vmf-linear-draws

data.frame(x = x) %>%
	ggplot() +
	geom_histogram(aes(x = x, y = after_stat(density)), col = "black",
		fill = NA, bins = 25) +
	geom_function(fun = d_target, args = list(kappa = kappa, d = d),
		lty = 2, xlim = c(1e-2 - 1, 1 - 1e-2)) +
	ylab("Density") +
	theme_minimal()
```

Plot proposal versus the target on the log-scale.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Proposal versus target on the log-scale for VMF example with linear
#|   majorizer.
#| label: fig-vmf-linear-proposal

log_h = function(x) { sapply(x, h$d, log = TRUE) }
log_f = function(x) { d_target(x, kappa = kappa, d = d, log = TRUE) }

ggplot() +
	geom_function(fun = log_f, col = "orange", lty = 1) +
	geom_function(fun = log_h, col = "black", lty = 2) +
	scale_x_continuous(limits = c(1e-2 - 1, 1 - 1e-2)) +
	xlab("x") +
	ylab("Density") +
	theme_minimal()
```

# Example: Lognormal-Normal Conditional Distribution {#sec-ln-norm}

The setting $Z = Y + \gamma$ is the basis of a modeling scenario considered by @DirectSamplingDAS2021 and @DPSimulation2022 where sensitive data are released under a measure of privacy protection. Here, $Y$ represents sensitive underlying data such as a tabulation of respondents' data collected by an official statistics agency and $\gamma$ is random noise added for privacy protection. The resulting $Z$ is considered protected and suitable for release. The objective is to carry out inference on $Y$ given an observed $Z = z$. The field of differential privacy studies mathematical criteria for privacy and the design of noise mechanisms which can satisfy those criteria [e.g., @DworkRoth2014]. @AbowdEtAl2022 describe recent work by the U.S. Census Bureau to implement differential privacy in the release of data from the decennial census. Our present motivation is to consider a simple but nontrivial sampling problem that arises in analysis of the released $z$; the interested reader is encouraged to see the given references as a starting point on privacy protection and differential privacy.

Suppose $Y$ and $\gamma$ are independently distributed with $Y \sim \text{Lognormal}(\mu, \sigma^2)$ and $\gamma \sim \text{N}(0, \lambda^2)$. The variance $\lambda^2$ of the noise mechanism is often known and provided with the noisy data under differential privacy. We will also assume that $\mu$ and $\sigma^2$ are known, though in practice these would need to be learned from an observed sample $z_1, \ldots, z_n$.

Suppose the target distribution is the conditional of $[Y \mid Z = z]$ which is given by
<!-- -->
\begin{align*}
f(y \mid z)
%
&\propto \frac{1}{\lambda \sqrt{2\pi}} \exp\left\{
-\frac{1}{2\lambda^2} (z - y)^2
\right\} \cdot
\frac{1}{y\sigma \sqrt{2\pi}} \exp\left\{
-\frac{1}{2\sigma^2} (\log y - \mu)^2
\right\} \mathbb{1}_{(0,\infty)}(y) \\
%
&\propto
\underbrace{\frac{1}{\lambda \sqrt{2\pi}} \exp\left\{
-\frac{1}{2\lambda^2} (z - y)^2
\right\}}_{g(y)} \cdot
\underbrace{\frac{1}{y} \exp\left\{
-\frac{1}{2\sigma^2} (\log y - \mu)^2
\right\} \mathbb{1}_{(0,\infty)}(y)}_{w(y)}.
\end{align*}
<!-- -->
Here we have decomposed $f$ into weight function
<!-- -->
\begin{math}
w(y) = \frac{1}{y} \exp\left\{ -\frac{1}{2\sigma^2} (\log y - \mu)^2 \right\} \mathbb{1}_{(0,\infty)}(y),
\end{math}
<!-- -->
from the Lognormal component---dropping some of the terms in its normalizing constant---and base distribution $g$ as $\text{N}(z, \lambda^2)$. It will sometimes be more convenient or numerically stable to work with $w$ on the log-scale; therefore, define
<!-- -->
\begin{align}
\zeta(y) = \log w(y)
= -\log y - \frac{(\log y - \mu)^2}{2 \sigma^2} + \log \mathbb{1}_{(0,\infty)}(y).
\label{eqn:ln-norm-log-weight-fn}
\end{align}

We will consider three variations of VWS sampler, which progresses from easier to implement to more computationally efficient. Section [-@sec-ln-norm-const-default] considers a constant majorizer where the constant for each region is obtained by numerical optimization. [@sec-ln-norm-const-custom] replaces numerical optimization with code for a closed-form solution. Section [-@sec-ln-norm-linear] makes use of a linear majorizer; this is somewhat more involved as it requires implementing a custom `Region`.

Before proceeding, let us fix the following values for the parameters.

```{r}
#| prompt: true
mu = 5
sigma2 = 0.5
lambda2 = 100
```

Jointly draw values $Y$ and $Z$ from the model; $Z$ is considered observed while $Y$ is latent and the objective for inference.

```{r}
set.seed(1234)
y_true = rlnorm(1, mu, sqrt(sigma2))
z = rnorm(1, y_true, sqrt(lambda2))
print(y_true)
print(z)
```

## Constant Majorizer with Numerical Optimization {#sec-ln-norm-const-default}

To implement this version of the sampler, let us first code the weight function. Note that calculations are carried out on the log-scale, and only exponentiated if explicitly requested.

```{r}
w = function(y, log = TRUE) {
	out = -log(y) - (log(y) - mu)^2 / (2*sigma2) + log(y > 0)
	out[y == 0] = -Inf
	if (log) { return(out) } else { return(exp(out)) }
}
```

Recall from [@sec-cpp-api-realconstregion] that a `univariate_helper` structure is used to construct an object of class `RealConstRegion` to provide necessary functions of the base distribution $g$. The `vws` package contains a built-in variant of `univariate_helper` named `normal_helper` for the normal distribution with mean and standard deviation parameters, which is appropriate for use in this problem.

```{r}
helper = normal_helper(mean = z, sd = sqrt(lambda2))
```

Before proceeding with the sampler, let us code the target density to assist in evaluating the distribution of the draws. To compute the normalizing constant, we will use Hermite quadrature via the `gauss.quad` function in the `statmod` package [@Smyth2005]. The integral $\psi = \int_{-\infty}^\infty q(x) e^{-x^2} dx$ is approximated as $\psi \approx \sum_{j=1}^Q \omega_j q(x_j)$ using quadrature points $x_1, \ldots, x_Q$ and weights $\omega_1, \ldots, \omega_Q$; to identify the function $q$, we have
<!-- -->
\begin{align*}
\psi &= \int_{-\infty}^\infty w(y) g(y) dy \\
%
&= \int_{-\infty}^\infty \ind(y > 0) \cdot \frac{1}{y}
\exp\left\{ -\frac{1}{2\sigma^2} (\log y - \mu)^2 \right\}
\frac{1}{\lambda \sqrt{2\pi}} \exp\left\{ -\frac{1}{2\lambda^2} (z - y)^2 \right\} dy \\
%
&= \int_{-\infty}^\infty \ind\left( z > \sqrt{2} \lambda x \right)
\cdot \frac{1}{z - \sqrt{2} \lambda x}
\exp\left\{ -\frac{1}{2\sigma^2} \left[\log\left( z - \sqrt{2} \lambda x \right) - \mu \right]^2 \right\}
\frac{1}{\sqrt{\pi}} e^{-x^2} dx,
\end{align*}
<!-- -->
by the transformation $y = z - \sqrt{2} \lambda x$, so that
<!-- -->
\begin{align*}
q(x) = \ind\left( z > \sqrt{2} \lambda x \right)
\cdot \frac{1}{z - \sqrt{2} \lambda x}
\exp\left\{ -\frac{1}{2\sigma^2} \left[\log\left( x - \sqrt{2} \lambda x \right) - \mu \right]^2 \right\}
\frac{1}{\sqrt{\pi}}.
\end{align*}
<!-- -->
Here is the associated code using `statmod` along with the normalized target density $f$.

```{r}
library(statmod)

q = function(x, log = FALSE) {
	tx = z - sqrt(2 * lambda2) * x
	out = log(tx > 0) - log(tx) - (log(tx) - mu)^2 / (2*sigma2) - 1/2 * log(pi)
	if (log) { return(out) } else { return(exp(out)) }
}

quad_out = gauss.quad(n = 10, kind = "hermite")
ww = quad_out$weights
xx = quad_out$nodes
psi = sum(ww * q(xx))

d_target = function(y, log = TRUE) {
	out = w(y, log = TRUE) + helper$d(y, log = TRUE) - log(psi)
	if (log) { return(out) } else { return(exp(out)) }
}
```

Let us instantiate a single region that consists of the full support $\Omega$ and construct a proposal based on it.

```{r}
support = RealConstRegion$new(a = 0, b = Inf, w = w, g = helper)
regions = list(support)
h_init = FMMProposal$new(regions)
```

We now refine the proposal using the `refine` function.

```{r}
refine_out = refine(h_init, N = 30, report = 10)
h = refine_out$h
```

The following plot shows the rate of decrease in bound \eqref{eqn:bound} over `N` steps of the refine call.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Rate of refine improvement for Lognormal-Normal example with
#|   constant majorizer.
#| label: fig-ln-norm-refine
data.frame(bdd = exp(refine_out$log_bdd_hist)) %>%
	mutate(step = row_number() - 1) %>%
	ggplot() +
	geom_line(aes(x = step, y = bdd)) +
	scale_y_continuous(n.breaks = 10) +
	xlab("Step") +
	ylab("Bound") +
	theme_minimal()
```

Let us also print the final bound that was obtained.

```{r}
bdd = tail(exp(refine_out$log_bdd_hist), 1)
cat("Upper bound for percent of rejections:", 100 * bdd)
```

Now proceed with rejection sampling.

```{r}
ctrl = rejection_control(report = 5000, extra_outputs = TRUE)
out = rejection(h, n = 10000, control = ctrl)
y = unlist(out$draws)
```

Let us compute the actual rejection rate.

```{r}
cat("Percent of proposed draws which were rejected:", 
	sum(out$rejects) / (length(y) + sum(out$rejects)) * 100)
```

Here is a plot comparing the empirical distribution of the sample to the target
density to ensure we have generated from the correct distribution.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Empirical distribution of draws versus target for Lognormal-Normal example
#|   with constant majorizer.
#| label: fig-ln-norm-constant-draws

gg = data.frame(y = y) %>%
	ggplot() +
	geom_histogram(aes(x = y, y = after_stat(density)), col = "black",
		fill = NA, bins = 25) +
	geom_function(fun = d_target, args = list(log = FALSE), lty = 2) +
	xlab("y") +
	ylab("Density") +
	theme_minimal()
print(gg)
```

Add an interval based on the $0.025$ and $0.975$ quantiles of the distribution $[Y \mid Z = z]$ approximated from the empirical quantiles of the draws. The value of the observed $z$ and the latent $y$ are also highlighted for reference.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Empirical distribution of draws versus target for Lognormal-Normal example
#|   with constant majorizer. Observed value of $z$ (blue line) and latent value
#|   of $y$ (red line) are displayed along with a 95\% interval (blue ribbon)
#|   based on draws from $[Y \mid Z = z]$.
#| label: fig-ln-norm-interval

interval_lo = quantile(y, probs = 0.025)
interval_hi = quantile(y, probs = 0.975)
gg + annotate("rect", xmin = interval_lo, xmax = interval_hi, ymin = 0,
		ymax = Inf, alpha = 0.1, fill = "blue") +
	geom_vline(xintercept = z, col = "blue", lwd = 1.05) +
	geom_vline(xintercept = y_true, col = "red", lwd = 1.05)
```

Plotting the proposal $h$ versus the target $f$ on the log-scale, the two distributions are seen to be very similar.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Proposal versus target on the log-scale for Lognormal-Normal example with
#|   constant majorizer.
#| label: fig-ln-norm-const-proposal

log_h = function(y) { sapply(y, h$d, log = TRUE) }
log_f = function(y) { d_target(y, log = TRUE) }

xlim = range(y)
ggplot() +
	geom_function(fun = log_f, col = "orange", lty = 1) +
	geom_function(fun = log_h, col = "black", lty = 2) +
	scale_x_continuous(limits = xlim) +
	xlab("y") +
	ylab("Density") +
	theme_minimal()
```

## Constant Majorizer with Custom Optimization {#sec-ln-norm-const-custom}

The log-weight function $\zeta$ from \eqref{eqn:ln-norm-log-weight-fn} can be both maximized and minimized in closed form. Coding it explicitly reduces computational overhead and avoids convergence issues from numerical optimization. This section will demonstrate how to override the default `optimize` method of `RealConstRegion`.

We have first derivative
<!-- -->
\begin{align*}
&\zeta'(y) = -\frac{1}{y}\left(
1 + \frac{\log y - \mu}{\sigma^2}
\right),
\end{align*}
<!-- -->
for $y \in (0, \infty)$. Let $y^* = \exp(\mu - \sigma^2)$; it is seen that $\zeta'(y)$ is positive when $y < y^*$, negative when $y > y^*$, and takes value zero at $y = y^*$. Then $y^*$ maximizes $\zeta(y)$ with maximum value $\zeta(y^*) = \sigma^2 / 2 - \mu$. Therefore, on a region $\mathcal{D}_j = (\alpha_{j-1}, \alpha_j]$ where both endpoints are smaller than $y^*$, the maximum of $\log w(y)$ is $\log w(\alpha_j)$ and the minimum is $\log w(\alpha_{j-1})$. On the other hand, for a region where both endpoints are larger than $y^*$, the maximum of $\log w(y)$ is $\log w(\alpha_{j-1})$ and the minimum is $\log w(\alpha_j)$.

Here is a plot of $\log w(y)$ with our selected $\mu$ and $\sigma^2$ values.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Weight function for Lognormal-Normal example on the log-scale, with the
#|   maximizer $x^* = exp(mu - sigma2)$ highlighted.
#| label: fig-ln-norm-weight

xlim = exp(mu - sigma2) + c(-10,10)
ggplot() +
	geom_function(fun = w, xlim = xlim) +
	geom_vline(xintercept = exp(mu - sigma2), lty = 2) +
	geom_hline(yintercept = sigma2 / 2 - mu, lty = 2) +
	xlab("y") +
	ylab(expression("log w(y)")) +
	theme_minimal()
```

```{.cpp include="examples/ln-norm/ln-norm-v2.cpp" code-line-numbers="true"}
```




## Linear Majorizer {#sec-ln-norm-linear}

::: {.callout-caution title="TBD"}
We need to pick finite endpoints I think ...
:::

Sections [-@sec-ln-norm-const-default] and [-@sec-ln-norm-const-custom] utilized a constant 
majorizer $\overline{w}_j = \max_{y \in \mathcal{D}_j} w(y)$ and minorizer $\underline{w}_j = \min_{y \in \mathcal{D}_j} w(y)$ for VWS sampling. Let us now consider a linear majorizer $\log \overline{w}_j(y) = \overline{\beta}_{0j} + \overline{\beta}_{1j} y$ and minorizer $\log \underline{w}_j(y) = \underline{\beta}_{0j} + \underline{\beta}_{1j} y$. This strategy is more involved to derive and implement, but often captures the weight function more effectively than a constant majorizer with fewer mixture components to yield more efficient proposals. We will find appropriate values of $\overline{\beta}_{0j}$, $\overline{\beta}_{1j}$, $\underline{\beta}_{0j}$, and $\underline{\beta}_{1j}$; compute $\overline{\xi}_j$ and $\underline{\xi}_j$ needed for the proposal mixture weights and the bound \eqref{eqn:bound}; and determine how to sample from the reweighted & truncated densities $g_1, \ldots, g_N$.

We first note that with majorizer $\overline{w}_j(y) = \exp\{ \overline{\beta}_{0j} + \overline{\beta}_{1j} y\}$, the truncated & reweighted density $g_j$ has the form
<!-- -->
\begin{align*}
g_j(y)
&\propto \overline{w}_j(y) g(y) \mathbb{1}_{(\alpha_{j-1}, \alpha_j]}(y) \\
%
&= \exp\{ \overline{\beta}_{0j} + \overline{\beta}_{1j} y\}
\phi(y \mid z, \lambda^2) \mathbb{1}_{(\alpha_{j-1}, \alpha_j]}(y) \\
%
&\propto \exp\{ \overline{\beta}_{1j} y\} \exp\left\{
-\frac{1}{2 \lambda^2} (y^2 - 2yz)
\right\} \mathbb{1}_{(\alpha_{j-1}, \alpha_j]}(y) \\
%
&\propto \exp\left\{
-\frac{1}{2 \lambda^2} \left[ y^2 - 2(z + \lambda^2 \overline{\beta}_{1j}) y \right]
\right\} \mathbb{1}_{(\alpha_{j-1}, \alpha_j]}(y).
\end{align*}
<!-- -->
This can be recognized as the density of $T_j \sim \text{N}(z + \lambda^2 \overline{\beta}_{1j}, \lambda^2)$ truncated to the interval $(\alpha_{j-1}, \alpha_j]$. Variates of $T_j$ can be generated using the CDF $\Phi(y \mid z + \lambda^2, \lambda^2)$ and its inverse $\Phi^{-1}(p \mid z + \lambda^2, \lambda^2)$ which can be accessed with `pnorm` and `qnorm` in R respectively. Next, it can be seen that $\zeta(y) = \log w(y)$ is either a convex or concave function, depending on the value of $y \in (0, \infty)$. The concavity or convexity of $\zeta$ on a region $\mathcal{D}_j$ can be used to determine a linear majorizing function. Proceeding from $\zeta'(y)$ given in [@sec-ln-norm-const-custom], the second derivative is seen to be
<!-- -->
\begin{align*}
&\zeta''(y) = -\frac{1}{y^2}\left(
\frac{\log y - \mu}{\sigma^2} + 1  - \frac{1}{\sigma^2}
\right),
\end{align*}
<!-- -->
with
<!-- -->
\begin{align*}
\zeta''(y) < 0
&\iff \frac{\log y - \mu}{\sigma^2} + 1  - \frac{1}{\sigma^2} > 0 \\
&\iff y < \exp(\mu - \sigma^2 + 1).
\end{align*}
<!-- -->
Therefore, $\zeta$ is concave when $y < \exp(\mu - \sigma^2 + 1)$ and convex when $y > \exp(\mu - \sigma^2 + 1)$. Let us assume that there are two initial regions $\mathcal{D}_1 = (0, \exp(\mu - \sigma^2 + 1)]$ and $\mathcal{D}_2 = (\exp(\mu - \sigma^2 + 1), \infty]$; this will ensure so that all partitions considered thereafter will consist of regions on which $\zeta$ is entirely concave or convex.

Before proceeding, the following integral is stated as a remark as it will be used several times.

::: {.callout-note #rem-normal-mgf-kernel}
Let $\phi(\cdot \mid \mu, \sigma^2)$ and $\Phi(\cdot \mid \mu, \sigma^2)$ be the density and CDF of $X \sim \text{N}(\mu, \sigma^2)$, respectively. If $a < b$ are scalars (possibly infinite), then 
<!-- -->
\begin{align*}
\int_a^b e^{tx} \phi(x \mid \mu, \sigma^2) dx
= \exp(\mu t + t^2 \sigma^2 / 2) \left\{ 
\Phi(b \mid \mu + t \sigma^2, \sigma^2) - \Phi(a \mid \mu + t \sigma^2, \sigma^2)
\right\}.
\end{align*}
<!-- -->
The special case $a = -\infty$ and $b = \infty$ yields the moment-generating function $M_X(t) = \exp(\mu t + t^2 \sigma^2 / 2)$ of $X$.
:::

The following construction assumes that $\zeta$ is finite and concave on the interval $\mathcal{D}_j = (\alpha_{j-1}, \alpha_j]$. A majorizer is obtained from
<!-- -->
\begin{align}
\zeta(y) &\leq \zeta(c) + (y - c) \nabla(c)
= \overline{\beta}_{j0} + \overline{\beta}_{j1} y,
\quad 
\overline{\beta}_{j0} = \zeta(c) - c \cdot \zeta'(c), \quad
\overline{\beta}_{j1} = \zeta'(c),
\label{eqn:ln-norm-linear-majorizer}
\end{align}
<!-- -->
where $c$ is a point in $\mathcal{D}_j$. In particular, let us consider the value of $c$ as
<!-- -->
\begin{align*}
c^* &= \argmin_{c \in \mathcal{D}_j} \int_{\mathcal{D}_j} | h_0(y) - f_0(y) | dy
\nonumber \\
%
&\equiv \argmin_{c \in \mathcal{D}_j} \Big\{ \log w(c) - c \nabla(c) + \log M_j(\nabla(c)) \Big\}.
\end{align*}
<!-- -->
Here, $M_j(s)$ is the moment generating function of random variable $T \sim g$ with support truncated to $(\alpha_{j-1}, \alpha_j]$:
<!-- -->
\begin{align*}
M_j(s)
%
&= \int_{\alpha_{j-1}}^{\alpha^j} e^{sy} \frac{
\phi(y \mid z, \lambda^2)
}{
\Phi(\alpha_j \mid z, \lambda^2) - \Phi(\alpha_{j-1} \mid z, \lambda^2)
} dy \\
%
&= \exp(z s + s^2 \lambda^2 / 2) 
\frac{
\Phi(\alpha_j \mid z + s \lambda^2, \lambda^2) - \Phi(\alpha_{j-1} \mid z + s \lambda^2, \lambda^2)
}{
\Phi(\alpha_j \mid z, \lambda^2) - \Phi(\alpha_{j-1} \mid z, \lambda^2)
},
\end{align*}
<!-- -->
using [@rem-normal-mgf-kernel]. A minorizer can be obtained by expressing $y = (1 - \lambda) \alpha_{j-1} + \lambda \alpha_j$ for $\lambda \in [0,1]$ so that $\lambda = (y - \alpha_{j-1}) / (\alpha_j - \alpha_{j-1})$ and
<!-- -->
\begin{align}
\zeta(y) &\geq (1-\lambda) \zeta(\alpha_{j-1}) + \lambda \zeta(\alpha_j) \nonumber \\
&= \zeta(\alpha_{j-1}) + \frac{y - \alpha_{j-1}}{\alpha_j - \alpha_{j-1}} [ \zeta(\alpha_j) - \zeta(\alpha_{j-1})]
= \underline{\beta}_{j0} + \underline{\beta}_{j1} y,
\label{eqn:ln-norm-linear-minorizer}
\end{align}
<!-- -->
with
<!-- -->
\begin{align*}
\underline{\beta}_{j0} = \zeta(\alpha_{j-1}) - \alpha_{j-1} \underline{\beta}_{j1}
\quad \text{and} \quad
\underline{\beta}_{j1} = \frac{\zeta(\alpha_j) - \zeta(\alpha_{j-1}) }{ \alpha_j - \alpha_{j-1} }.
\end{align*}
<!-- -->
If $\zeta$ is convex on $\mathcal{D}_j$ rather than concave, the roles of \eqref{eqn:ln-norm-linear-majorizer} and \eqref{eqn:ln-norm-linear-minorizer} are switched so that \eqref{eqn:ln-norm-linear-majorizer} is minorizer and \eqref{eqn:ln-norm-linear-minorizer} is majorizer.

Using [@rem-normal-mgf-kernel], we have
<!-- -->
\begin{align}
\overline{\xi}_j
&= \int_{\alpha_{j-1}}^{\alpha_j}
\exp\{ \overline{\beta}_{0j} + \overline{\beta}_{1j} y \}
\phi(y \mid z, \lambda^2) dy
\nonumber \\
&= \exp\left\{
\overline{\beta}_{0j} + z \overline{\beta}_{1j} + \overline{\beta}_{1j}^2 \lambda^2 / 2
\right\}
\left\{ 
\Phi(\alpha_j \mid z + \overline{\beta}_{1j} \lambda^2, \lambda^2)
- \Phi(\alpha_{j-1} \mid z + \overline{\beta}_{1j} \lambda^2, \lambda^2)
\right\}
\label{eqn:ln-norm-xi-upper}
\end{align}
<!-- -->
and
<!-- -->
\begin{align}
\underline{\xi}_j
&= \int_{\alpha_{j-1}}^{\alpha_j}
\exp\{ \underline{\beta}_{0j} + \underline{\beta}_{1j} y \}
\phi(y \mid z, \lambda^2) dy
\nonumber \\
&= \exp\left\{
\underline{\beta}_{0j} + z \underline{\beta}_{1j} + \underline{\beta}_{1j}^2 \lambda^2 / 2
\right\}
\left\{ 
\Phi(\alpha_j \mid z + \underline{\beta}_{1j} \lambda^2, \lambda^2)
- \Phi(\alpha_{j-1} \mid z + \underline{\beta}_{1j} \lambda^2, \lambda^2)
\right\}.
\label{eqn:ln-norm-xi-lower}
\end{align}
<!-- -->
The results obtained thus far can be used to implement the necessary operations
of a `Region` which are listed in Table `?`. We name the resulting
class `CustomLinearRegion`. Operations for `CustomLinearRegion` are summarized
in [@tbl-ln-norm-custom-region-methods] and the complete code may be found in
the following file.

```{r}
source("../inst/examples/lnorm-norm-linear/CustomLinearRegion.R")
```

: Methods of the `CustomLinearRegion` class. {#tbl-ln-norm-custom-region-methods tbl-colwidths="[20,80]"}

-------------------------------------------------------------------------------
Method            Description
-----             -----
`w`               $w(y) = \frac{1}{y} \exp\left\{ -\frac{1}{2\sigma^2}
                  (\log y - \mu)^2 \right\} \mathbb{1}_{(0,\infty)}(y)$.

`w_major`         $\overline{w}_j(y) = \exp\{
                  \overline{\beta}_{0j} + \overline{\beta}_{1j} y\}$.

`d_base`          Density of $\text{N}(z, \lambda^2)$.

`r`               Generate draws from
                  $\text{N}(z + \lambda^2 \overline{\beta}_{1j},
                  \lambda^2)$ truncated to $(\alpha_{j-1}, \alpha_j]$.

`d`               Compute the density of
                  $\text{N}(z + \lambda^2 \overline{\beta}_{1j},
                  \lambda^2)$ truncated to $(\alpha_{j-1}, \alpha_j]$.

`s`               $\mathbb{1}_{\alpha_{j-1}, \alpha_j}(y)$.

`xi_upper`        Compute $\overline{\xi}_j$ via \eqref{eqn:ln-norm-xi-upper}.

`xi_lower`        Compute $\underline{\xi}_j$ via \eqref{eqn:ln-norm-xi-lower}.

`bifurcate`       Midpoint rule from [@sec-cpp-api-realconstregion].

`is_bifurcatable` Return `TRUE`.
-------------------------------------------------------------------------------

Let us proceed with a demonstration of the VWS sampler based on `CustomLinearRegion`. First create two initial regions around the point $\exp(\mu - \sigma^2 + 1)$, where $w(y)$ switches from log-concave to log-convex.
 
```{r}
y_star = exp(mu - sigma2 + 1)
region1 = CustomLinearRegion$new(a = 1e-6, b = y_star, mu, sigma2, z, lambda2)
region2 = CustomLinearRegion$new(a = y_star, b = 1e6, mu, sigma2, z, lambda2)
regions = list(region1, region2)
```

Construct the proposal and refine it.

```{r}
h_init = FMMProposal$new(regions)
refine_out = refine(h_init, N = 30)
h = refine_out$h
```

Plot the rate of refinement over the steps.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Rate of refine improvement on the log-scale for Lognormal-Normal
#|   example with linear majorizer.
#| label: fig-ln-norm-linear-refine

data.frame(bdd = refine_out$log_bdd_hist) %>%
	mutate(step = row_number() - 1) %>%
	ggplot() +
	geom_line(aes(x = step, y = bdd)) +
	scale_y_continuous(n.breaks = 10) +
	xlab("Step") +
	ylab("Log of Bound") +
	theme_minimal()
```

Proceed with rejection sampling using the resulting proposal.

```{r}
ctrl = rejection_control(report = 5000, extra_outputs = TRUE)
out = rejection(h, n = 10000, control = ctrl)
y = unlist(out$draws)
```

Print the actual rejection rate. Notice that it is substantially lower than the rate achieved in [@sec-ln-norm-const-default].

```{r}
cat("Percent of proposed draws rejected:",
	sum(out$rejects) / (length(y) + sum(out$rejects)) * 100)
```

Plot the empirical distribution of the draws overlaid with the target density.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Empirical distribution of draws versus target for Lognormal-Normal example
#|   with linear majorizer.
#| label: fig-ln-norm-linear-draws

data.frame(y = y) %>%
	ggplot() +
	geom_histogram(aes(x = y, y = after_stat(density)), col = "black",
		fill = NA, bins = 25) +
	geom_function(fun = d_target, args = list(log = FALSE), lty = 2) +
	ylab("y") +
	ylab("Density") +
	theme_minimal()
```

Finally, comparing the unnormalized proposal $h$ and target density $f$ on the log-scale, we notice that visually they are almost indistinguishable.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Proposal versus target on the log-scale for Lognormal-Normal example with
#|   linear majorizer.
#| label: fig-ln-norm-proposal

log_h = function(y) { sapply(y, h$d, log = TRUE) }
log_f = function(y) { d_target(y, log = TRUE) }

xlim = range(y)
ggplot() +
	geom_function(fun = log_f, lty = 1, col = "orange", lwd = 1.2) +
	geom_function(fun = log_h, lty = 2, col = "black", lwd = 1.2) +
	scale_x_continuous(limits = xlim) +
	xlab("y") +
	ylab("Density") +
	theme_minimal()
```

# Example: Bessel Count Distribution {#sec-bessel}

::: {.callout-caution title="TBD"}
Under construction. The example is working, but the writing needs to be fleshed
out.
:::

TBD: this sampling problem comes up in @Devroye2002.

```{r}
#| prompt: true
source("../inst/examples/bessel/functions.R")
```

In this example, we consider generating from the Bessel density described by
@Devroye2002 as
<!-- -->
\begin{align*}
f(x) = \frac{(a/2)^{2x+\nu}}{I_v(a) \cdot x! \cdot \Gamma(x + \nu + 1)}
\cdot \mathbb{1}_{\mathbb{N}}(x), \quad
\nu > -1, \quad
a > 0,
\end{align*}
<!-- -->
where we denote the positive integers as $\mathbb{N} = \{ 0, 1, 2, \ldots \}$
and
<!-- -->
\begin{align*}
I_v(a) = \sum_{x=0}^\infty \frac{(a/2)^{2x+\nu}}{x! \cdot \Gamma(x + \nu + 1)}
\end{align*}
<!-- -->
is a modified Bessel function of the first kind.

At the time the paper was written, @Devroye2002 considered it difficult to
generate exact draws from this distribution. He develops what appears to be a
customized accept-reject method after establishing properties of the
distribution. We can draw from this distribution fairly easily without such an
in-depth analysis.

Our approach is to decompose the density into
<!-- -->
\begin{align*}
f(x)
&= \frac{(a/2)^{2x+\nu}}{I_v(a) \cdot x! \cdot \Gamma(x + \nu + 1)}
\cdot \mathbb{1}_{\mathbb{N}}(x) \\
%
&\propto 
\frac{e^{a^2/4} (a/2)^\nu}{\Gamma(x + \nu + 1)}
\frac{(a/2)^{2x} e^{-a^2/4}}{x!} \mathbb{1}_{\mathbb{N}}(x) \\
%
&\propto w(x) g(x),
\end{align*}
<!-- -->
where $g(x) = \frac{(a^2/4)^x e^{-a^2/4}}{x!} \mathbb{1}_{\mathbb{N}}(x)$
represents a $\text{Poisson}(a^2/4)$ base distribution and weight function
specified on the log scale as by $\log w(x) = -\log \Gamma(x + \nu + 1)$.
Notice that we can disregard many of the normalizing constants with this
sampler.

We can explicitly describe computations involved in the sampler.

- Make regions of the form $\mathcal{D}_j = (\alpha_{j-1}, \alpha_j]$.
- Compute $P(T \in \mathcal{D}_j)$.
- Optimize $w(x)$ on $\mathcal{D}_j$ to obtain $\overline{w}_j$ and
	  $\underline{w}_j$.
- Draw from Poisson truncated to $\mathcal{D}_j$.
- Refine algorithm that uses integer midpoint.

We can also show some displays of how the sampler performs.

- Volume and/or log volume as we increase $N$ with refining.
- The exact density versus the proposal density for several values of $N$ along
  the refinement path.
- The number of draws rejected in practice along the refinement path (say, if
  we request a large number such as $n = 10^7$).

It looks like we can capture the distribution almost exactly by covering the
entire support with a not-too-large choice of $N$, but this will depend on the
parameters $a$ and $\nu$. When we have refined to this point, it becomes
extremely rare to reject any candidates.

Consider giving background information about the Bessel distribution to show
why it was of special interest to Devroye.

```{r}
#| out-width: 60%
#| fig-cap: |
#|   Rate of refine improvement on the log-scale for Bessel example.
#| label: fig-bessel-refine

nu = -0.5
lambda = 10

helper = poisson_helper(lambda^2 / 4)

w = function(x, log = TRUE) {
	out = -lgamma(x + nu + 1) + lambda^2 / 4 + nu * log(lambda / 2)
	if (log) { return(out) } else { return(exp(out)) }
}

support = IntConstRegion$new(a = -1, b = Inf, w = w, g = helper)
regions = list(support)

h_init = FMMProposal$new(regions)
refine_out = refine(h_init, N = 30, report = 10)
h = refine_out$h

data.frame(logbdd = refine_out$log_bdd_hist) %>%
	mutate(step = row_number() - 1) %>%
	ggplot() +
	geom_line(aes(x = step, y = logbdd)) +
	scale_y_continuous(n.breaks = 10) +
	xlab("Step") +
	ylab("Log of Bound") +
	theme_minimal()

ctrl = rejection_control(max_rejects = 10000, report = 5000)
out = rejection(h, n = 10000, control = ctrl)
x = unlist(out)
```

Plot the empirical distribution of the draws with the target density.

```{r}
#| out-width: 60%
#| fig-cap: Empirical distribution of draws versus target for Bessel example.
#| label: fig-bessel-draws

n = length(x)
tab_out = factor(x, levels = seq(0, 11)) |> table()
x_vals = tab_out |> names() |> as.integer()
d_vals_emp = (tab_out / n) |> as.numeric()
d_vals = d_bessel(x_vals, a = lambda, nu = nu)

data.frame(x = x_vals, d_emp = d_vals_emp, d = d_vals) %>%
	ggplot() +
	geom_point(aes(x = x, y = d), pch = 1) +
	geom_point(aes(x = x, y = d_emp), pch = 3) +
	ylab("Probability") +
	theme_minimal()
```

Plot proposal versus the target on the log-scale.

```{r}
#| out-width: 60%
#| fig-cap: Proposal versus target on the log-scale for Bessel example.
#| label: fig-bessel-proposal

log_h = function(x) { sapply(x, h$d, log = TRUE) }
log_f = function(x) { d_bessel(x, a = lambda, nu = nu, log = TRUE) }

df = data.frame(x = x_vals) %>%
	mutate(log_h_vals = log_h(x)) %>%
	mutate(log_f_vals = log_f(x))

ggplot(df) +
	geom_point(aes(x, log_h_vals), pch = 1) +
	geom_point(aes(x, log_f_vals), pch = 3) +
	xlab("x") +
	ylab("Density") +
	theme_minimal()
```


## Constant Majorizer with Numerical Optimization {#sec-bessel-const-default}

```{.cpp include="examples/bessel/bessel-v1.cpp" code-line-numbers="true"}
```

## Constant Majorizer with Custom Optimization {#sec-bessel-const-custom}

**TBD:** Is it tractable for this problem?

```{.cpp include="examples/bessel/bessel-v2.cpp" code-line-numbers="true"}
```

## Linear Majorizer {#sec-bessel-linear}

**TBD:** Is it tractable for this problem?


# Conclusions

::: {.callout-caution title="TBD"}
Content needed
:::

# Acknowledgments {.unnumbered .unlisted}

::: {.callout-caution title="TBD"}
Content needed
:::

# References
